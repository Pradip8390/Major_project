# -*- coding: utf-8 -*-
"""EDA1_Data1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wWCQkc0tkvnXWg3Gw0ZCTTTn8carMSb1
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
file_path = "Dataset_project.csv"
df = pd.read_csv(file_path)

# Basic info and structure
print("Dataset Info:")
print(df.info())
print("\nFirst 5 Rows:")
print(df.head())

# Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())

# Length of questions and responses
df['pattern_length'] = df['pattern'].apply(len)
df['response_length'] = df['response/0'].apply(len)

# Distribution of question lengths
plt.figure(figsize=(8, 6))
sns.histplot(df['pattern_length'], bins=20, kde=True)
plt.title('Distribution of Question Lengths')
plt.xlabel('Length of Questions')
plt.ylabel('Frequency')
plt.show()

# Distribution of response lengths
plt.figure(figsize=(8, 6))
sns.histplot(df['response_length'], bins=20, kde=True)
plt.title('Distribution of Response Lengths')
plt.xlabel('Length of Responses')
plt.ylabel('Frequency')
plt.show()

# Most common words in patterns
from collections import Counter
import itertools

all_words = list(itertools.chain.from_iterable([pattern.split() for pattern in df['pattern']]))
word_freq = Counter(all_words)
common_words = pd.DataFrame(word_freq.most_common(10), columns=['Word', 'Frequency'])

plt.figure(figsize=(8, 6))
sns.barplot(x='Frequency', y='Word', data=common_words)
plt.title('Top 10 Most Common Words in Questions')
plt.show()

print("\nTop 10 Most Common Words in Questions:")
print(common_words)